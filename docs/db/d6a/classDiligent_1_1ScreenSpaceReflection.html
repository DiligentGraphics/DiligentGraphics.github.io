<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Diligent Engine: Diligent::ScreenSpaceReflection Class Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../clipboard.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Diligent Engine
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('db/d6a/classDiligent_1_1ScreenSpaceReflection.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="../../d3/d7e/classDiligent_1_1ScreenSpaceReflection-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">Diligent::ScreenSpaceReflection Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Implements <a href="https://github.com/DiligentGraphics/DiligentFX/tree/master/PostProcess/ScreenSpaceReflection">screen-space reflection post-process effect</a>.  
 <a href="#details">More...</a></p>

<p><code>#include &lt;ScreenSpaceReflection.hpp&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d3/d71/structDiligent_1_1ScreenSpaceReflection_1_1CreateInfo.html">CreateInfo</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create info.  <a href="../../d3/d71/structDiligent_1_1ScreenSpaceReflection_1_1CreateInfo.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d1/d50/structDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes.html">RenderAttributes</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Render attributes.  <a href="../../d1/d50/structDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-types" name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a993695a4851f4ef7bd036f866adbad3b" id="r_a993695a4851f4ef7bd036f866adbad3b"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a993695a4851f4ef7bd036f866adbad3b">FEATURE_FLAGS</a> : Uint32 { <a class="el" href="#a993695a4851f4ef7bd036f866adbad3ba2004d8945dc394d431694e3c97a2a093">FEATURE_FLAG_NONE</a> = 0u
, <b>FEATURE_FLAG_PREVIOUS_FRAME</b> = 1u &lt;&lt; 0u
, <b>FEATURE_FLAG_HALF_RESOLUTION</b> = 1u &lt;&lt; 1u
 }</td></tr>
<tr class="memdesc:a993695a4851f4ef7bd036f866adbad3b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Feature flags that control the behavior of the effect.  <a href="#a993695a4851f4ef7bd036f866adbad3b">More...</a><br /></td></tr>
<tr class="separator:a993695a4851f4ef7bd036f866adbad3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ac1c2be7ce6beedcb5c1d9d21d3547fe6" id="r_ac1c2be7ce6beedcb5c1d9d21d3547fe6"><td class="memItemLeft" align="right" valign="top"><a id="ac1c2be7ce6beedcb5c1d9d21d3547fe6" name="ac1c2be7ce6beedcb5c1d9d21d3547fe6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>ScreenSpaceReflection</b> (<a class="el" href="../../de/dc2/classDiligent_1_1IRenderDevice.html">IRenderDevice</a> *pDevice, const <a class="el" href="../../d3/d71/structDiligent_1_1ScreenSpaceReflection_1_1CreateInfo.html">CreateInfo</a> &amp;CI)</td></tr>
<tr class="memdesc:ac1c2be7ce6beedcb5c1d9d21d3547fe6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a new instance of the <a class="el" href="../../db/d6a/classDiligent_1_1ScreenSpaceReflection.html" title="Implements screen-space reflection post-process effect.">ScreenSpaceReflection</a> class. <br /></td></tr>
<tr class="separator:ac1c2be7ce6beedcb5c1d9d21d3547fe6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad55b833c9b6481c288017c2708e39a8e" id="r_ad55b833c9b6481c288017c2708e39a8e"><td class="memItemLeft" align="right" valign="top"><a id="ad55b833c9b6481c288017c2708e39a8e" name="ad55b833c9b6481c288017c2708e39a8e"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>PrepareResources</b> (<a class="el" href="../../de/dc2/classDiligent_1_1IRenderDevice.html">IRenderDevice</a> *pDevice, <a class="el" href="../../d9/dcf/classDiligent_1_1IDeviceContext.html">IDeviceContext</a> *pDeviceContext, PostFXContext *pPostFXContext, <a class="el" href="#a993695a4851f4ef7bd036f866adbad3b">FEATURE_FLAGS</a> FeatureFlags)</td></tr>
<tr class="memdesc:ad55b833c9b6481c288017c2708e39a8e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prepares resources for the effect. <br /></td></tr>
<tr class="separator:ad55b833c9b6481c288017c2708e39a8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adfb57fc4e35d7bce90459acee41a252f" id="r_adfb57fc4e35d7bce90459acee41a252f"><td class="memItemLeft" align="right" valign="top"><a id="adfb57fc4e35d7bce90459acee41a252f" name="adfb57fc4e35d7bce90459acee41a252f"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>Execute</b> (const <a class="el" href="../../d1/d50/structDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes.html">RenderAttributes</a> &amp;RenderAttribs)</td></tr>
<tr class="memdesc:adfb57fc4e35d7bce90459acee41a252f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Executes the screen-space reflection effect. <br /></td></tr>
<tr class="separator:adfb57fc4e35d7bce90459acee41a252f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89d36cb16f281465612de12ef605996d" id="r_a89d36cb16f281465612de12ef605996d"><td class="memItemLeft" align="right" valign="top"><a id="a89d36cb16f281465612de12ef605996d" name="a89d36cb16f281465612de12ef605996d"></a>
<a class="el" href="../../dc/d24/structDiligent_1_1ITextureView.html">ITextureView</a> *&#160;</td><td class="memItemRight" valign="bottom"><b>GetSSRRadianceSRV</b> () const</td></tr>
<tr class="memdesc:a89d36cb16f281465612de12ef605996d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the shader resource view of the screen-space reflection texture. <br /></td></tr>
<tr class="separator:a89d36cb16f281465612de12ef605996d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:ab4c4e2cc2c489db8b10e913bc14aa74e" id="r_ab4c4e2cc2c489db8b10e913bc14aa74e"><td class="memItemLeft" align="right" valign="top"><a id="ab4c4e2cc2c489db8b10e913bc14aa74e" name="ab4c4e2cc2c489db8b10e913bc14aa74e"></a>
static bool&#160;</td><td class="memItemRight" valign="bottom"><b>UpdateUI</b> (HLSL::ScreenSpaceReflectionAttribs &amp;SSRAttribs, <a class="el" href="#a993695a4851f4ef7bd036f866adbad3b">FEATURE_FLAGS</a> &amp;FeatureFlags, <a class="el" href="../../d7/dca/namespaceDiligent.html#a9e27ac38f8dccaa4b4f8e967cd1e868e">Uint32</a> &amp;DisplayMode)</td></tr>
<tr class="memdesc:ab4c4e2cc2c489db8b10e913bc14aa74e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds the ImGui controls to the UI. <br /></td></tr>
<tr class="separator:ab4c4e2cc2c489db8b10e913bc14aa74e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Implements <a href="https://github.com/DiligentGraphics/DiligentFX/tree/master/PostProcess/ScreenSpaceReflection">screen-space reflection post-process effect</a>. </p>
<h1><a class="anchor" id="autotoc_md172"></a>
Screen Space Reflections</h1>
<p><img src="../../media/ssr-logo.jpg" alt="alt text" title="A screenshot showing the final composite of the SSR reflections into a scene." class="inline"/></p>
<h2><a class="anchor" id="autotoc_md173"></a>
Table of contents</h2>
<ul>
<li>Introduction<ul>
<li>Motivation</li>
<li>Supported platforms</li>
</ul>
</li>
<li>Integration guidelines<ul>
<li>Input resources</li>
<li>Host API</li>
</ul>
</li>
<li>Implementation details<ul>
<li>Algorithm structure</li>
<li>Preparation for ray tracing<ul>
<li>Blue noise texture generation</li>
<li>Hierarchical depth generation</li>
<li>Stencil mask generation and roughness extraction</li>
</ul>
</li>
<li>Ray tracing</li>
<li>Denoising<ul>
<li>Spatial reconstruction</li>
<li>Temporal accumulation</li>
<li>Cross-bilateral filtering</li>
</ul>
</li>
</ul>
</li>
<li>Possible improvements</li>
<li><a class="el" href="../../de/d6b/README.html#references">References</a></li>
</ul>
<h2><a class="anchor" id="autotoc_md174"></a>
Introduction</h2>
<h3><a class="anchor" id="autotoc_md175"></a>
Motivation</h3>
<p>We needed to add screen space reflections to our project with the following requirements:</p><ul>
<li>Compatibility with WebGL</li>
<li>Rough surfaces support</li>
<li><p class="startli">The execution time should not exceed 2ms at Full HD resolution on devices equivalent to RTX 2070.</p>
<p class="startli">We used AMD's implementation of Screen Space Reflections as the basis for our implementation <a href="https://gpuopen.com/manuals/fidelityfx_sdk/fidelityfx_sdk-page_techniques_stochastic-screen-space-reflections/"><b>[AMD-SSSR]</b></a>. We recommend reading AMD's documentation and also a more detailed review of the algorithm by Kostas Anagnostou <a href="https://interplayoflight.wordpress.com/2022/09/28/notes-on-screenspace-reflections-with-fidelityfx-sssr/"><b>[Kostas Anagnostou, SSSR]</b></a> to better understand the following sections. Since WebGL doesn't support compute shaders, we had to make some compromises for compatibility. Please refer to implementation details section for further insights.</p>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md176"></a>
Integration guidelines</h2>
<h3><a class="anchor" id="autotoc_md177"></a>
Input resources</h3>
<h4><a class="anchor" id="autotoc_md178"></a>
Input Textures</h4>
<p>The following table enumerates all external inputs required by SSR.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><b>Name</b>   </th><th class="markdownTableHeadNone"><b>Format</b>   </th><th class="markdownTableHeadNone"><b>Notes</b>    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Color buffer   </td><td class="markdownTableBodyNone"><code>APPLICATION SPECIFIED</code>   </td><td class="markdownTableBodyNone">The HDR render target of the current frame containing the scene radiance    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Depth buffer   </td><td class="markdownTableBodyNone"><code>APPLICATION SPECIFIED (1x FLOAT)</code>   </td><td class="markdownTableBodyNone">The depth buffer for the current frame provided by the application. The data should be provided as a single floating point value, the precision of which is under the application's control    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Normal buffer   </td><td class="markdownTableBodyNone"><code>APPLICATION SPECIFIED (3x FLOAT)</code>   </td><td class="markdownTableBodyNone">The normal buffer for the current frame provided by the application in the [-1.0, +1.0] range. Normals should be in world space    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Material parameters buffer   </td><td class="markdownTableBodyNone"><code>APPLICATION SPECIFIED (1x FLOAT)</code>   </td><td class="markdownTableBodyNone">The roughness buffer for the current frame provided by the application. By default, SSR expects the roughness to be the perceptual / artist set roughness <b>squared</b>. If your <a class="el" href="../../dd/d7f/classDiligent_1_1GBuffer.html" title="G-buffer manages a set of render targets.">GBuffer</a> stores the artist set roughness directly, please set the <code>IsRoughnessPerceptual</code> field of the <code>ScreenSpaceReflectionAttribs</code> structure to <code>true</code>. The user is also expected to provide a channel to sample from the material parameters buffer through the <code>RoughnessChannel</code> field of the <code>ScreenSpaceReflectionAttribs</code> structure.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Motion vectors   </td><td class="markdownTableBodyNone"><code>APPLICATION SPECIFIED (2x FLOAT)</code>   </td><td class="markdownTableBodyNone">The 2D motion vectors for the current frame provided by the application in the NDC space   </td></tr>
</table>
<h4><a class="anchor" id="autotoc_md179"></a>
HLSL::ScreenSpaceReflectionAttribs</h4>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><b>Name</b>   </th><th class="markdownTableHeadNone"><b>Notes</b>    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Depth buffer thickness   </td><td class="markdownTableBodyNone">A bias for accepting hits. Larger values can cause streaks, lower values can cause holes    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Roughness threshold   </td><td class="markdownTableBodyNone">Regions with a roughness value greater than this threshold won't spawn rays    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Most detailed mip   </td><td class="markdownTableBodyNone">The most detailed MIP map level in the depth hierarchy. Perfect mirrors always use 0 as the most detailed level    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Roughness perceptual   </td><td class="markdownTableBodyNone">A boolean to describe the space used to store roughness in the materialParameters texture. If false, we assume roughness squared was stored in the G-Buffer    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Roughness channel   </td><td class="markdownTableBodyNone">The channel to read the roughness from the materialParameters texture    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Max traversal intersections   </td><td class="markdownTableBodyNone">Caps the maximum number of lookups that are performed from the depth buffer hierarchy. Most rays should terminate after approximately 20 lookups    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Importance sample bias   </td><td class="markdownTableBodyNone">This parameter is aimed at reducing noise by modify sampling in the ray tracing stage. Increasing the value increases the deviation from the ground truth but reduces the noise    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Spatial reconstruction radius   </td><td class="markdownTableBodyNone">The value controls the kernel size in the spatial reconstruction step. Increasing the value increases the deviation from the ground truth but reduces the noise    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Temporal radiance stability factor   </td><td class="markdownTableBodyNone">A factor to control the accmulation of history values of radiance buffer. Higher values reduce noise, but are more likely to exhibit ghosting artefacts    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Temporal variance stability factor   </td><td class="markdownTableBodyNone">A factor to control the accmulation of history values of variance buffer. Higher values reduce noise, but are more likely to exhibit ghosting artefacts    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Bilateral cleanup spatial sigma factor   </td><td class="markdownTableBodyNone">This parameter represents the standard deviation ($\sigma$) in the Gaussian kernel, which forms the spatial component of the bilateral filter   </td></tr>
</table>
<p>The effect can be configured using the <code><a class="el" href="#a993695a4851f4ef7bd036f866adbad3b" title="Feature flags that control the behavior of the effect.">ScreenSpaceReflection::FEATURE_FLAGS</a></code> enumeration. The following table lists the flags and their descriptions.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><b>Name</b>   </th><th class="markdownTableHeadNone"><b>Notes</b>    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>FEATURE_FLAG_PREVIOUS_FRAME</code>   </td><td class="markdownTableBodyNone">When using this flag, you only need to pass the color buffer of the previous frame. We find the intersection using the depth buffer of the current frame, and when an intersection is found, we make the corresponding offset by the velocity vector at the intersection point, for sampling from the color buffer.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>FEATURE_FLAG_HALF_RESOLUTION</code>   </td><td class="markdownTableBodyNone">When this flag is used, ray tracing step is executed at half resolution   </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md180"></a>
Host API</h3>
<p>To integrate SSR into your project, you need to include the following necessary header files: </p><div class="fragment"><div class="line"><span class="preprocessor">#include &quot;PostFXContext.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;<a class="code" href="../../d3/df7/ScreenSpaceReflection_8hpp.html">ScreenSpaceReflection.hpp</a>&quot;</span></div>
<div class="ttc" id="aScreenSpaceReflection_8hpp_html"><div class="ttname"><a href="../../d3/df7/ScreenSpaceReflection_8hpp.html">ScreenSpaceReflection.hpp</a></div></div>
</div><!-- fragment --> <div class="fragment"><div class="line"><span class="keyword">namespace </span>HLSL</div>
<div class="line">{</div>
<div class="line"><span class="preprocessor">#include &quot;Shaders/Common/public/BasicStructures.fxh&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;Shaders/PostProcess/ScreenSpaceReflection/public/ScreenSpaceReflectionStructures.fxh&quot;</span></div>
<div class="line">} <span class="comment">// namespace HLSL</span></div>
</div><!-- fragment --><p>Now, create the necessary objects: </p><div class="fragment"><div class="line">m_PostFXContext = std::make_unique&lt;PostFXContext&gt;(m_pDevice);</div>
<div class="line">m_SSR           = std::make_unique&lt;ScreenSpaceReflection&gt;(m_pDevice);</div>
</div><!-- fragment --><p>Next, call the methods to prepare resources for the <code>PostFXContext</code> and <code><a class="el" href="../../db/d6a/classDiligent_1_1ScreenSpaceReflection.html" title="Implements screen-space reflection post-process effect.">ScreenSpaceReflection</a></code> objects. This needs to be done every frame before starting the rendering process. </p><div class="fragment"><div class="line">{</div>
<div class="line">    PostFXContext::FrameDesc FrameDesc;</div>
<div class="line">    FrameDesc.Index  = m_CurrentFrameNumber; <span class="comment">// Current frame number.</span></div>
<div class="line">    FrameDesc.Width  = SCDesc.Width;         <span class="comment">// Current screen width.</span></div>
<div class="line">    FrameDesc.Height = SCDesc.Height;        <span class="comment">// Current screen height.</span></div>
<div class="line">    m_PostFXContext-&gt;PrepareResources(m_pDevice, FrameDesc, PostFXContext::FEATURE_FLAG_NONE);</div>
<div class="line"> </div>
<div class="line">    <a class="code hl_enumeration" href="#a993695a4851f4ef7bd036f866adbad3b">ScreenSpaceReflection::FEATURE_FLAGS</a> ActiveFeatures = ...;</div>
<div class="line">    m_SSR-&gt;PrepareResources(m_pDevice, m_pImmediateContext, m_PostFXContext.get(), ActiveFeatures);</div>
<div class="line">}</div>
<div class="ttc" id="aclassDiligent_1_1ScreenSpaceReflection_html_a993695a4851f4ef7bd036f866adbad3b"><div class="ttname"><a href="#a993695a4851f4ef7bd036f866adbad3b">Diligent::ScreenSpaceReflection::FEATURE_FLAGS</a></div><div class="ttdeci">FEATURE_FLAGS</div><div class="ttdoc">Feature flags that control the behavior of the effect.</div><div class="ttdef"><b>Definition</b> ScreenSpaceReflection.hpp:560</div></div>
</div><!-- fragment --><p>Now we invoke the method <code>PostFXContext::Execute</code>. At this stage, some intermediate resources necessary for all post-processing objects dependent on <code>PostFXContext</code> are calculated. This method can take a constant buffer directly containing an array from the current and previous cameras (for this method, you can refer to this section of the code [<a href="https://github.com/DiligentGraphics/DiligentSamples/blob/380b0a05b6c72d80fd6d574d7343ead77d6dd7eb/Tutorials/Tutorial27_PostProcessing/src/Tutorial27_PostProcessing.cpp#L164">0</a>] and [<a href="https://github.com/DiligentGraphics/DiligentSamples/blob/380b0a05b6c72d80fd6d574d7343ead77d6dd7eb/Tutorials/Tutorial27_PostProcessing/src/Tutorial27_PostProcessing.cpp#L228">1</a>]). Alternatively, you can pass the corresponding pointers <code>const HLSL::CameraAttribs* pCurrCamera</code> and <code>const HLSL::CameraAttribs* pPrevCamera</code> for the current and previous cameras, respectively. You also need to pass the depth of the current and previous frames (the depth buffers should not contain transparent objects), and a buffer with motion vectors in NDC space, into the corresponding <code>ITextureView* pCurrDepthBufferSRV</code>, <code>ITextureView* pPrevDepthBufferSRV</code>, <code>ITextureView* pMotionVectorsSRV</code> pointers.</p>
<div class="fragment"><div class="line">{</div>
<div class="line">    PostFXContext::RenderAttributes PostFXAttibs;</div>
<div class="line">    PostFXAttibs.pDevice             = m_pDevice;</div>
<div class="line">    PostFXAttibs.pDeviceContext      = m_pImmediateContext;</div>
<div class="line">    PostFXAttibs.pCameraAttribsCB    = m_FrameAttribsCB;  <span class="comment">// m_Resources[RESOURCE_IDENTIFIER_CAMERA_CONSTANT_BUFFER].AsBuffer();</span></div>
<div class="line">    PostFXAttibs.pCurrDepthBufferSRV = m_CurrDepthBuffer; <span class="comment">// m_Resources[RESOURCE_IDENTIFIER_DEPTH0 + CurrFrameIdx].GetTextureSRV();</span></div>
<div class="line">    PostFXAttibs.pPrevDepthBufferSRV = m_PrevDepthBuffer; <span class="comment">// m_Resources[RESOURCE_IDENTIFIER_DEPTH0 + PrevFrameIdx].GetTextureSRV();</span></div>
<div class="line">    PostFXAttibs.pMotionVectorsSRV   = m_MotionBuffer;    <span class="comment">// m_GBuffer-&gt;GetBuffer(GBUFFER_RT_MOTION_VECTORS)-&gt;GetDefaultView(TEXTURE_VIEW_SHADER_RESOURCE);</span></div>
<div class="line">    m_PostFXContext-&gt;Execute(PostFXAttibs);</div>
<div class="line">}</div>
</div><!-- fragment --><p>Now we need to directly invoke the ray tracing stage. To do this, we call the <code><a class="el" href="#adfb57fc4e35d7bce90459acee41a252f" title="Executes the screen-space reflection effect.">ScreenSpaceReflection::Execute</a></code> method. Before this, we need to fill the passed structures <code>ScreenSpaceReflectionAttribs</code> and <code><a class="el" href="../../d1/d50/structDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes.html" title="Render attributes.">ScreenSpaceReflection::RenderAttributes</a></code> with the necessary data. Please read the Input resources section for a more detailed description of each parameter </p><div class="fragment"><div class="line">{</div>
<div class="line">    HLSL::ScreenSpaceReflectionAttribs SSRAttribs{};</div>
<div class="line">    SSRAttribs.RoughnessChannel      = 0;</div>
<div class="line">    SSRAttribs.IsRoughnessPerceptual = <span class="keyword">true</span>;</div>
<div class="line"> </div>
<div class="line">    <a class="code hl_struct" href="../../d1/d50/structDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes.html">ScreenSpaceReflection::RenderAttributes</a> SSRRenderAttribs{};</div>
<div class="line">    SSRRenderAttribs.<a class="code hl_variable" href="../../d1/d50/structDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes.html#a73a22c6a663ed217e7901e5ef2e3ca7a">pDevice</a>            = m_pDevice;</div>
<div class="line">    SSRRenderAttribs.pDeviceContext     = m_pImmediateContext;</div>
<div class="line">    SSRRenderAttribs.pPostFXContext     = m_PostFXContext.get();</div>
<div class="line">    SSRRenderAttribs.pColorBufferSRV    = m_GBuffer-&gt;GetBuffer(GBUFFER_RT_RADIANCE)-&gt;GetDefaultView(<a class="code hl_enumvalue" href="../../d7/dca/namespaceDiligent.html#a6863a150530d5abe1cc5627b23ebce68acd9fed7b22b88f0a8b40d0d98d3c1243">TEXTURE_VIEW_SHADER_RESOURCE</a>);</div>
<div class="line">    SSRRenderAttribs.pDepthBufferSRV    = m_GBuffer-&gt;GetBuffer(GBUFFER_RT_DEPTH)-&gt;GetDefaultView(<a class="code hl_enumvalue" href="../../d7/dca/namespaceDiligent.html#a6863a150530d5abe1cc5627b23ebce68af974362f40fbd2a6062e8220124a86aa">TEXTURE_VIEW_DEPTH_STENCIL</a>);</div>
<div class="line">    SSRRenderAttribs.pNormalBufferSRV   = m_GBuffer-&gt;GetBuffer(GBUFFER_RT_NORMAL)-&gt;GetDefaultView(<a class="code hl_enumvalue" href="../../d7/dca/namespaceDiligent.html#a6863a150530d5abe1cc5627b23ebce68acd9fed7b22b88f0a8b40d0d98d3c1243">TEXTURE_VIEW_SHADER_RESOURCE</a>);</div>
<div class="line">    SSRRenderAttribs.pMaterialBufferSRV = m_GBuffer-&gt;GetBuffer(GBUFFER_RT_MATERIAL_DATA)-&gt;GetDefaultView(<a class="code hl_enumvalue" href="../../d7/dca/namespaceDiligent.html#a6863a150530d5abe1cc5627b23ebce68acd9fed7b22b88f0a8b40d0d98d3c1243">TEXTURE_VIEW_SHADER_RESOURCE</a>);</div>
<div class="line">    SSRRenderAttribs.pMotionVectorsSRV  = m_GBuffer-&gt;GetBuffer(GBUFFER_RT_MOTION_VECTORS)-&gt;GetDefaultView(<a class="code hl_enumvalue" href="../../d7/dca/namespaceDiligent.html#a6863a150530d5abe1cc5627b23ebce68acd9fed7b22b88f0a8b40d0d98d3c1243">TEXTURE_VIEW_SHADER_RESOURCE</a>);</div>
<div class="line">    SSRRenderAttribs.pSSRAttribs        = &amp;SSRAttribs;</div>
<div class="line">    m_SSR-&gt;Execute(SSRRenderAttribs);</div>
<div class="line">}</div>
<div class="ttc" id="anamespaceDiligent_html_a6863a150530d5abe1cc5627b23ebce68acd9fed7b22b88f0a8b40d0d98d3c1243"><div class="ttname"><a href="../../d7/dca/namespaceDiligent.html#a6863a150530d5abe1cc5627b23ebce68acd9fed7b22b88f0a8b40d0d98d3c1243">Diligent::TEXTURE_VIEW_SHADER_RESOURCE</a></div><div class="ttdeci">@ TEXTURE_VIEW_SHADER_RESOURCE</div><div class="ttdef"><b>Definition</b> GraphicsTypes.h:327</div></div>
<div class="ttc" id="anamespaceDiligent_html_a6863a150530d5abe1cc5627b23ebce68af974362f40fbd2a6062e8220124a86aa"><div class="ttname"><a href="../../d7/dca/namespaceDiligent.html#a6863a150530d5abe1cc5627b23ebce68af974362f40fbd2a6062e8220124a86aa">Diligent::TEXTURE_VIEW_DEPTH_STENCIL</a></div><div class="ttdeci">@ TEXTURE_VIEW_DEPTH_STENCIL</div><div class="ttdef"><b>Definition</b> GraphicsTypes.h:335</div></div>
<div class="ttc" id="astructDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes_html"><div class="ttname"><a href="../../d1/d50/structDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes.html">Diligent::ScreenSpaceReflection::RenderAttributes</a></div><div class="ttdoc">Render attributes.</div><div class="ttdef"><b>Definition</b> ScreenSpaceReflection.hpp:575</div></div>
<div class="ttc" id="astructDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes_html_a73a22c6a663ed217e7901e5ef2e3ca7a"><div class="ttname"><a href="../../d1/d50/structDiligent_1_1ScreenSpaceReflection_1_1RenderAttributes.html#a73a22c6a663ed217e7901e5ef2e3ca7a">Diligent::ScreenSpaceReflection::RenderAttributes::pDevice</a></div><div class="ttdeci">IRenderDevice * pDevice</div><div class="ttdoc">Render device that may be used to create new objects needed for this frame, if any.</div><div class="ttdef"><b>Definition</b> ScreenSpaceReflection.hpp:577</div></div>
</div><!-- fragment --><p>Now, you can directly obtain a <code><a class="el" href="../../dc/d24/structDiligent_1_1ITextureView.html" title="Texture view interface.">ITextureView</a></code> on the texture containing the SSR result using the method <code><a class="el" href="#a89d36cb16f281465612de12ef605996d" title="Returns the shader resource view of the screen-space reflection texture.">ScreenSpaceReflection::GetSSRRadianceSRV</a></code>. After this, you can apply SSR in your rendering pipeline using the formula below.</p>
<div class="fragment"><div class="line">\large \text{SpecularRadiance} = \sum_{i=1}^{n} (F_0 * LUT_{BRDF}.x + LUT_{BRDF}.y) \times \text{lerp}(\text{Environment}_i, \text{SSR}, \text{Confidence})</div>
</div><!-- fragment --><p> The alpha channel of the SSR texture stores $Confidence$. You can read about how to compute the $LUT_{BRDF}$ in this article <a href="https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf"><b>[Brian Karis, PBR]</b></a> page 7. The parameter $F_0$ is the Fresnel coefficient.</p>
<h2><a class="anchor" id="autotoc_md181"></a>
Implementation details</h2>
<h3><a class="anchor" id="autotoc_md182"></a>
Algorithm structure</h3>
<p>The algorithm can be divided into three main parts</p><ol type="1">
<li>Preparation for ray tracing<ul>
<li>Blue noise texture generation</li>
<li>Hierarchical depth generation</li>
<li>Stencil mask generation and roughness extraction</li>
</ul>
</li>
<li>Ray Tracing</li>
<li>Denoising<ul>
<li>Spatial reconstruction</li>
<li>Temporal accumulation</li>
<li>Cross-bilateral filtering</li>
</ul>
</li>
</ol>
<h3><a class="anchor" id="autotoc_md183"></a>
Preparation for ray tracing</h3>
<p>In this stage, we prepare the necessary resources for the ray tracing stage</p>
<h4><a class="anchor" id="autotoc_md184"></a>
Blue noise texture generation</h4>
<p>Blue noise aims to uniformly distribute sample points across the sampling domain. This is in direct contrast to white noise, which exhibits clumps and voids. Clumped samples result in redundant data, while voids represent missing data. Blue noise circumvents these issues by maintaining a roughly uniform distribution in space, thus avoiding clumps and voids.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Comparison of sampling with white noise and blue noise    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-blue-noise.jpg" alt="" class="inline"/>   </td></tr>
</table>
<p>AMD's implementation prepares a 128×128 texture with screen-space (animated) blue noise (<a href="https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/sdk/include/FidelityFX/gpu/sssr/ffx_sssr_prepare_blue_noise_texture.h">PrepareBlueNoiseTexture</a>), based on the work of Eric <a href="https://eheitzresearch.wordpress.com/762-2/"><b>[Eric Heitz, Blue Noise]</b></a>. This will be used later to drive the stochastic sampling of the specular lobe.</p>
<p>In general, we follow the AMD's approach, with the exception that we generate two blue noise textures simultaneously and use a pixel shader <a href="https://github.com/DiligentGraphics/DiligentFX/blob/master/Shaders/Common/private/ComputeBlueNoiseTexture.fx"><b>ComputeBlueNoiseTexture.fx</b></a> instead of a compute shader. The second blue noise texture is required for SSAO, as our goal is to prevent potential correlation between pixels obtained in the SSR and SSAO steps. AMD uses <code>uint32_t</code> format to store static arrays such as <code>SobolBuffer</code> (256 * 256 * 4 bytes = 256 KiB) and <code>ScramblingTileBuffer</code> (128 * 128 * 4 * 8 bytes = 512 KiB), which respectively adds 768 KiB to the executable file. We changed format of the static arrays from <code>uint32_t</code> to <code>uint8_t</code>, and also noticed that <code>SobolBuffer</code> is used only along one dimension. Consequently, we have reduced the added size to the executable file to 128 KiB by making these optimizations.</p>
<h4><a class="anchor" id="autotoc_md185"></a>
Hierarchical depth generation</h4>
<p>The hierarchical depth buffer is a mip chain where each pixel is the minimum (maximum for reserved depth) of the previous level's 2×2 area depths (mip 0 corresponds to the screen-sized, original depth buffer). It will be used later to speed up raymarching, but can also be used in many other techniques, like GPU occlusion culling.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Depth mip chain    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-hierachical-depth.jpg" alt="" class="inline"/>   </td></tr>
</table>
<p>We recommend reading this article <a href="https://miketuritzin.com/post/hierarchical-depth-buffers/"><b>[Mike Turitzin, Hi-Z]</b></a>, as computing a hierarchical buffer for resolutions not divisible by 2 is not so trivial. The original AMD algorithm uses SPD <a href="https://gpuopen.com/manuals/fidelityfx_sdk/fidelityfx_sdk-page_techniques_single-pass-downsampler/"><b>[AMD-SPD]</b></a> to convolve the depth buffer (<a href="https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/sdk/include/FidelityFX/gpu/sssr/ffx_sssr_depth_downsample.h">DepthDownsample</a>). SPD allows us to compute it in a single <b>Dispatch</b> call, but since we can't use compute shaders we use a straightforward approach. We calculate each mip level using a pixel shader <a href="https://github.com/DiligentGraphics/DiligentFX/blob/master/Shaders/PostProcess/ScreenSpaceReflection/private/SSR_ComputeHierarchicalDepthBuffer.fx"><b>SSR_ComputeHierarchicalDepthBuffer.fx</b></a>, using the previous mip level as an input.</p>
<h4><a class="anchor" id="autotoc_md186"></a>
Stencil mask generation and roughness extraction</h4>
<p>The original algorithm starts with a classification pass (<a href="https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/sdk/include/FidelityFX/gpu/sssr/ffx_sssr_classify_tiles.h"><b>ClassifyTiles</b></a>). This step writes pixels that will participate in the ray tracing step and subsequent denoising stages to a global buffer (our denoiser differs from the AMD's implementation, but the underlying idea remains the same). The decision of whether a pixel needs a ray or not is based on the roughness; very rough surfaces don't get any rays and instead rely on the prefiltered environment map as an approximation. Once this done we are (almost) ready to ray march, the only problem is that we don’t know the size of the global array of pixels to trace on the CPU to launch a <code>Dispatch</code>. For that reason, the technique fills a buffer with indirect arguments, with data already known to the GPU and uses a <code>DispatchIndirect</code> instead. The indirect arguments buffer is populated during the <a href="https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/sdk/include/FidelityFX/gpu/sssr/ffx_sssr_prepare_indirect_args.h"><b>PrepareIndirectArgs</b></a> pass. Nothing particular to mention here apart from that it adds 2 entries to the indirect buffer, one for the pixels to trace and one for the tiles to denoise later.</p>
<p>Since we cannot use compute shaders, we have made compromises. We use a stencil mask to mark pixels that should participate in subsequent calculations. To do this, we first clear stencil buffer with <code>0x0</code> value, and then we run <a href="https://github.com/DiligentGraphics/DiligentFX/blob/master/Shaders/PostProcess/ScreenSpaceReflection/private/SSR_ComputeStencilMaskAndExtractRoughness.fx"><b>SSR_ComputeStencilMaskAndExtractRoughness.fx</b></a> with stencil test enabled for writing and with the corresponding stencil buffer attached. If the roughness of the current pixel is less than <code>RoughnessThreshold</code>, we write the value <code>0xFF</code> to the stencil buffer; otherwise, the stencil buffer retains its previous value of <code>0x0</code>. In subsequent steps, we enable stencil test for reading with the <code>COMPARISON_FUNC_EQUAL</code> function for the value <code>0xFF</code>. While writing to the stencil buffer, we also write the roughness to a separate render target. The separate texture allows us to simplify the code for roughness sampling in subsequent steps of the algorithm and improves performance.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Stencil mask for SSR   </th><th class="markdownTableHeadCenter">Final renderend image with SSR    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-stencil-0.jpg" alt="" class="inline"/>   </td><td class="markdownTableBodyCenter"><img src="../../media/ssr-stencil-1.jpg" alt="" class="inline"/>   </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md187"></a>
Ray tracing</h3>
<p>We have now reached the most crucial part of the algorithm, for which all the previous preparations were made. We almost entirely repeat the (<a href="https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/sdk/include/FidelityFX/gpu/sssr/ffx_sssr_intersect.h"><b>Intersect</b></a>) step with some exceptions; refer to the difference section.</p>
<p>Our goal is to solve the rendering equation for the specular part (GGX Microfacet BRDF)</p>
<div align="center"> <b>Specular part of rendering equation</b> </div><p>$$ \large L_{o,s}(\mathbf{v}) = \int_{\Omega} \frac{F(\mathbf{v,h})D(\mathbf{h})G(\mathbf{l,v})}{4 \langle \mathbf{n} \cdot \mathbf{l} \rangle \langle \mathbf{n} \cdot \mathbf{v} \rangle} L_i(\mathbf{l}) \cos(\theta) d\omega $$</p>
<p>Unfortunately, it is impossible to calculate the rendering equation accurately in real-time, so AMD's SSSR uses Split-Sum-Approximation. We strongly recommend reading the original article by <a href="https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf"><b>[Brian Karis, PBR]</b></a>, as well as viewing this presentation <a href="https://www.mathematik.uni-marburg.de/~thormae/lectures/graphics1/graphics_10_2_eng_web.html#1"><b>[Thorsten Thormählen, IBL]</b></a> starting from slide 29, if you are interested in the derivation of the resulting formula</p>
<div align="center"> <b>Split-Sum-Approximation </b> </div><p>$$ \begin{gather} \large \frac{1}{N} \sum_{n=1}^{N} \frac{F(\mathbf{v}, \mathbf{h}) G(\mathbf{l}, \mathbf{v}) \langle \mathbf{v} \cdot \mathbf{h} \rangle}{\langle \mathbf{n} \cdot \mathbf{h} \rangle \langle \mathbf{n} \cdot \mathbf{v} \rangle} L_i(\mathbf{l}) \approx \underbrace{\frac{1}{N} \sum_{n=1}^{N} L_i(\mathbf{l})}_{T_1} \cdot \underbrace{\frac{1}{N} \sum_{n=1}^{N} \frac{F(\mathbf{v}, \mathbf{h}) G(\mathbf{l}, \mathbf{v}) \langle \mathbf{v} \cdot \mathbf{h} \rangle}{\langle \mathbf{n} \cdot \mathbf{h} \rangle \langle \mathbf{n} \cdot \mathbf{v} \rangle}}_{T_2} \ \large \text{with } \mathbf{h} = \begin{pmatrix} \sin(\theta_h)\cos(\phi_h) \ \sin(\theta_h)\sin(\phi_h) \ \large \cos(\theta_h) \end{pmatrix} \text{ and } \mathbf{l} = \text{reflect}(-\mathbf{v}, \mathbf{h}) \ \large \text{where } \phi_h = 2\pi \chi_x(n) \text{ and } \theta_h = \arccos\left(\frac{1 - \chi_y(n)}{\sqrt{\chi_y(n)(\alpha^2-1)+1}}\right) \end{gather} $$</p>
<p>In the expression shown in the image above, we see two sums, $T_{1}$ and $T_{2}$. Let's first consider the sum $T_{2}$. In the original article by Epic Games, the $T_{2}$ sum is divided into two separate sums, $T_{2,r}$ and $T_{2,g}$ (see below), by inserting the Schlick approximation for $F$:</p>
<div align="center"> <b>Split-Sum for BRDF Integration Map </b> </div><p>$$ \begin{align} &amp;\large T_2 = \frac{1}{N} \sum_{n=1}^{N} \frac{F(\mathbf{v}, \mathbf{h}) G(\mathbf{l}, \mathbf{v}) \langle \mathbf{v} \cdot \mathbf{h} \rangle}{\langle \mathbf{n} \cdot \mathbf{h} \rangle \langle \mathbf{n} \cdot \mathbf{v} \rangle} \ &amp;\large = F_0 \underbrace{\frac{1}{N} \sum_{n=1}^{N} \frac{G(\mathbf{l}, \mathbf{v}) \langle \mathbf{v} \cdot \mathbf{h} \rangle}{\langle \mathbf{n} \cdot \mathbf{h} \rangle \langle \mathbf{n} \cdot \mathbf{v} \rangle} \left( 1.0 - (1.0 - \langle \mathbf{v} \cdot \mathbf{h}\rangle )^5 \right)}_{T_{2,r}} \ &amp;\large + \underbrace{\frac{1}{N} \sum_{n=1}^{N} \frac{G(\mathbf{l}, \mathbf{v}) \langle \mathbf{v} \cdot \mathbf{h} \rangle}{\langle \mathbf{n} \cdot \mathbf{h} \rangle \langle \mathbf{n} \cdot \mathbf{v} \rangle} (1.0 - \langle \mathbf{v} \cdot \mathbf{h} \rangle^5) }_{T_{2,g}} \end{align} $$</p>
<p>The result of the pre-computation $T_{2,r}$ and $T_{2,g}$ can be stored in the red and green channel of a LUT texture, which is parameterized in x-direction by $⟨n⋅v⟩$ an in y-direction by the roughness $r_{p}$ (both in the range [0.0, 1.0]). Here you can take a look at the source code for computing this texture (<a href="https://github.com/DiligentGraphics/DiligentFX/blob/master/Shaders/PBR/private/PrecomputeBRDF.psh">PrecomputeBRDF.psh</a>), known as a BRDF Integration Map. The original sum $T_{2}$ is obtained using Fresnel coefficient $F_{0}$. Since our algorithm does not require surface information, the calculation of the $T_{2}$ sum must be carried out on the user's side.</p>
<p>Let's now turn to the sum $T_{1}$. In the article by Epic Games, it is calculated for the Environment Map, taking into account roughness, and they call this the Pre-Filtered Environment Map. In our case, we need to calculate the $T_{1}$ sum for each pixel explicitly. Since the ray tracing step is expensive, we compute only one sample incoming radiace $L_i(\mathbf{l})$ per pixel, and the accumulation of the sum $T_1$ is performed in the temporal accumulation step, using spatial reprojection. For computing of incoming radiance $L_i(\mathbf{l})$, we must generate a half-vector $\mathbf{h}$ for every pixel, then use it to derive the light vector $\mathbf{l} = \text{reflect}(-\mathbf{v},\mathbf{h})$. Now we need to find the intersection of the ray based on the world-space position of the pixel and the generated light vector $\mathbf{l}$, with the scene using hierarchical ray marching. If an intersection occurs, we should take the corresponding radiance value from the <code>ColorBuffer</code>; otherwise, we take the value from the EnvironmentMap (our algorithm does not require an Environment Map as in the AMD implementation, we use <code>Confidence</code> color channel for resolve radiance; refer to the difference section).</p>
<p>An attentive reader has likely noticed $\chi_x$ and $\chi_y$ in the Split-Sum-Approximation equation for generating the half-vector $\mathbf{h}$. These are precisely the values from the animated blue noise texture that we generated before. Using the blue noise texture, we accordingly generate the half vector. The method just described has a significant drawback; please refer to the image below.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Invalid ray    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-unoccluded.jpg" alt="" class="inline"/>   </td></tr>
</table>
<p>As seen in the image above, the previously proposed method for creating samples to calculate incoming radiance generates rays that are below the horizon. To solve this problem, we use the method <a href="http://jcgt.org/published/0007/04/01/"><b>[Eric Heitz, VNDF]</b></a> for generating half-vector $\mathbf{h}$. This method suggests creating the half-vector in such a way where $\mathbf{v} = (v_x, v_y, v_z)$:</p>
<div class="fragment"><div class="line">\begin{align*}</div>
<div class="line">    &amp;\large \mathbf{v}_h = \frac{1}{\sqrt{\alpha^2 v_x^2 + \alpha^2 v_y^2 + v_z^2}} \begin{pmatrix} \alpha v_x \\ \alpha v_y \\ v_z \end{pmatrix} \\</div>
<div class="line">    &amp;\large l = v_{h, x}^2 + v_{h, y}^2 \\</div>
<div class="line">    &amp;\large \mathbf{T}_1 = \begin{cases} </div>
<div class="line">        \frac{1}{\sqrt{l}} \begin{pmatrix} -v_{h,y} \\ v_{h, x} \\ 0 \end{pmatrix}, &amp; \text{if } l &gt; 0 \\</div>
<div class="line">        \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}, &amp; \text{otherwise}</div>
<div class="line">    \end{cases} \\</div>
<div class="line">    &amp;\large \mathbf{T}_2 = \mathbf{v}_h \times \mathbf{T}_1 \\</div>
<div class="line">    &amp;\large r = \sqrt{\chi_x(n)} \\</div>
<div class="line">    &amp;\large \phi = 2 \pi \chi_y(n) \\</div>
<div class="line">    &amp;\large t_1 = r \cos(\phi) \\</div>
<div class="line">    &amp;\large t_2 = (1 - 0.5(1 + v_{h.z}))\sqrt{1 - t_1^2} + 0.5(1 + v_{h,z}) r \sin(\phi) \\</div>
<div class="line">    &amp;\large \mathbf{h}_h = t_1 \mathbf{T}_1 + t_2 \mathbf{T}_2 + \sqrt{\max(0, 1 - t_1^2 - t_2^2)} \mathbf{v}_h \\</div>
<div class="line">    &amp;\large \mathbf{h} = \frac{1}{\sqrt{\alpha^2 h_{h, x}^2 + \alpha^2 h_{h, y}^2 + \max(0, h_{h, z}^2)}} \begin{pmatrix} \alpha h_{h,x} \\ \alpha h_{h,y} \\ \max(0, h_{h,z}) \end{pmatrix}</div>
<div class="line">\end{align*}</div>
</div><!-- fragment --><p>Let's directly move on to the stage of hierarchical ray marching. This method allows us to efficiently skip empty areas. Raymarching starts at mip 0 (highest resolution) of the depth buffer. If no collision is detected, we drop to a lower resolution mip and continue raymarching. Again, if no collision is detected we continue dropping to lower resolution mips until we detect one. If we do, we climb back up to a higher resolution mip and continue from there. This allows quickly skipping empty space in the depth buffer. If you're unclear about how hierarchical ray marching works, take a look at the animated slides below.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Hierarchical depth buffer traversal    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-hierarchical-traversal.gif" alt="" class="inline"/>   </td></tr>
</table>
<p>After finding the intersection point of the ray with the scene, we calculate the screen coordinate and sample incoming radiance from <code>ColorBuffer</code> and write it as the result for the current pixel (the original implementation samples from the Environment Map if no intersection occurs; in our implementation, this is not the case). Also, we record the length of the ray, which will be needed during the denoising stages. You can view the code implementing this step here: <a href="https://github.com/DiligentGraphics/DiligentFX/blob/master/Shaders/PostProcess/ScreenSpaceReflection/private/SSR_ComputeIntersection.fx"><b>SSR_ComputeIntersection.fx</b></a>.</p>
<p>Key differences with the AMD implementation in the ray tracing step:</p><ul>
<li>Since the scene may contain multiple environment maps, each of which may interact with a different pixel, we decided not to pass the environment map to the SSR stage (although this means we lose grazing specular reflections in areas where ray does not intersect with scene). Instead, we write a confidence value (roughly speaking, <code>1</code> if an intersection occurred, <code>0</code> if not) in the alpha channel of the resulting texture. This value will later be used by the user to interpolate between the value from the SSR and the Environment Map.</li>
<li>Since we do not use AMD's denoiser but our own, we needed to record the result $p$ - PDF of the generated half vector $\mathbf{h}$ and light vector $\mathbf{l}$. Read section spatial reconstruction</li>
<li>We added GGX Bias parameter that allows us to reduce the variance a bit. We recommend you watching this video to understand how it works <a href="https://youtu.be/AzXEao-WKRc?t=1122"><b>[EA-SSRR]</b></a></li>
</ul>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Specular radiance after ray tracing   </th><th class="markdownTableHeadCenter">Confidence    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-intersection.jpg" alt="" class="inline"/>   </td><td class="markdownTableBodyCenter"><img src="../../media/ssr-confidence.jpg" alt="" class="inline"/>   </td></tr>
</table>
<h3><a class="anchor" id="autotoc_md188"></a>
Denoising</h3>
<p>As we can see, the image obtained from the ray tracing step is quite noisy. The goal of the next stage of the algorithm is to reduce that noise.</p>
<h4><a class="anchor" id="autotoc_md189"></a>
Spatial reconstruction</h4>
<p>At this step of the denoising algorithm, we make the assumption that closely located surface points have the same visibility, so we attempt to accumulate the incoming radiance of each point from its nearby points.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Same visibility in the red zone    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-visibility.jpg" alt="" class="inline"/>   </td></tr>
</table>
<p>This assumption introduces bias into the final image, but despite this drawback, it significantly reduces noise on surfaces with high roughness. To accumulate samples, we use an approach from <a href="https://youtu.be/AzXEao-WKRc?t=746"><b>[EA-SSRR]</b></a>.They suggest using this formula to accumulate samples:</p>
<div class="fragment"><div class="line">\Large L_{o, s}(\mathbf{v}) \approx \frac{\sum_{n=1}^{N} \frac{L_i(\mathbf{l}) f_r(\mathbf{v}, \mathbf{l}) \langle \mathbf{n} \cdot \mathbf{l} \rangle}{p_n}}{\sum_{n=1}^{N} \frac{f_r( \mathbf{v}, \mathbf{l}) \langle \mathbf{n} \cdot \mathbf{l} \rangle}{p_n}} T_2</div>
</div><!-- fragment --><p>As can be noted, to calculate the sums in front of the $T_2$, we already have all the necessary components $L_i$, $l$, $p$, as we have mentioned in the ray tracing step. You can view the source code for the computation of this stage: <a href="https://github.com/DiligentGraphics/DiligentFX/blob/master/Shaders/PostProcess/ScreenSpaceReflection/private/SSR_ComputeSpatialReconstruction.fx"><b>SSR_ComputeSpatialReconstruction.fx</b></a> It can be noted that we accumulate samples in screen space, and we also use a variable radius and a variable number of samples depending on the surface roughness when computing this expression. Also, during the sum accumulation, we calculate the variance and search for the maximum ray length (from ray tracing stage, we pass non-normalized ray with length (<code>SurfaceHitWS</code> - <code>RayOriginWS</code>)), and then we record the results in separate textures. The variance will be needed for cross-bilateral filtering pass. The ray length will be required during the temporal accumulation stage for parallax correction.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Specular radiance after spatial reconstruction   </th><th class="markdownTableHeadCenter">Variance    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-spatial-reconstruction.jpg" alt="" class="inline"/>   </td><td class="markdownTableBodyCenter"><img src="../../media/ssr-variance.jpg" alt="" class="inline"/>   </td></tr>
</table>
<h4><a class="anchor" id="autotoc_md190"></a>
Temporal accumulation</h4>
<p>At this step, we accumulate the image obtained after the spatial reconstruction with the image obtained at this step but from a previous moment in time. We rely on the temporal coherence of frames, as the information between frames does not change significantly. One might wonder why we don't simply use the TAA (Temporal Anti-Aliasing) algorithm. A typical reprojection method, commonly employed in TAA, is not adequately effective for reflections. This is because the objects reflected move according to their own depth, rather than the depth of the surfaces reflecting them, which is what's recorded in the depth buffer. Therefore, we need to ascertain the previous frame's location of these reflected objects. Overall, our implementation of temporal accumulation is similar to the implementation by AMD <a href="https://github.com/GPUOpen-LibrariesAndSDKs/FidelityFX-SDK/blob/main/sdk/include/FidelityFX/gpu/denoiser/ffx_denoiser_reflections_reproject.h">Reproject</a>.</p>
<p>We use the approach from this presentation <a href="https://www.ea.com/seed/news/seed-dd18-presentation-slides-raytracing"><b>[EA-HYRTR]</b></a>, slide 45. At a high level, we can divide the current stage into four parts: 1) Calculate the statistics of the current pixel (mean, standard deviation, variance) based on color buffer. 2) Compute intensity from the previous frame for two screen space points relative to the current pixel's position. The first position is formed by subtracting the motion vector from the current pixel's position, while the second position is calculated based on the ray length, which we computed during the ray tracing stage and modified during the spatial reprojection stage. 3) Based on the statistics of the current pixel and the intensity values for two points, we select the point on which we will base the reprojection. 4) If the reprojection is successful, we interpolate the values between the intensity from the selected point (which we calculated in the previous step) and the intensity value for the current pixel. If the reprojection is not successful, we record the intensity value from the current pixel.</p>
<p>For implementation details, look at the source code: <a href="https://github.com/DiligentGraphics/DiligentFX/blob/master/Shaders/PostProcess/ScreenSpaceReflection/private/SSR_ComputeTemporalAccumulation.fx"><b>SSR_ComputeTemporalAccumulation.fx</b></a>.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Specular radiance after temporal accumulation    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-temporal-accumulation.jpg" alt="" class="inline"/>   </td></tr>
</table>
<h4><a class="anchor" id="autotoc_md191"></a>
Cross-bilateral filtering</h4>
<p>This stage is based on a standard bilateral filter <a href="https://en.wikipedia.org/wiki/Bilateral_filter"><b>[Wiki, Bilateral filter]</b></a> with the following specifics:</p><ul>
<li>We use variance calculated during the spatial reconstruction stage to determine the $\sigma$ for the spatial kernel $G_s$ of the bilateral filter.</li>
<li>Since the image being processed is quite noisy, instead of using the pixel intensity of the processed image to create the range kernel $G_r$, we use the depth buffer and the normals buffer to form the kernel. We took the functions for generate the range kernel $G_r$ from the SVGF algorithm <a href="https://cg.ivd.kit.edu/publications/2017/svgf/svgf_preprint.pdf"><b>[Christoph Schied, SVGF]</b></a>, expressions $(3)$ and $(4)$</li>
</ul>
<p>You can find the implementation here: <a href="https://github.com/DiligentGraphics/DiligentFX/blob/master/Shaders/PostProcess/ScreenSpaceReflection/private/SSR_ComputeBilateralCleanup.fx"><b>SSR_ComputeBilateralCleanup.fx</b></a></p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Specular radiance after bilater filtering    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-bilateral-filter.jpg" alt="" class="inline"/>   </td></tr>
</table>
<p>The final frame with reflections is shown below.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Final image after tone mapping    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"><img src="../../media/ssr-result.jpg" alt="" class="inline"/>   </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md192"></a>
Possible improvements</h2>
<ul>
<li>Add support for reversed depth buffer</li>
<li>Add support for compressed normal map</li>
<li>Add dynamic resolution for the raytracing stage, which will increase performance on weaker GPU</li>
<li>Spatial reconstruction step uses screen space to accumulate samples. Try to perform accumulation in world coords, this should reduce bias</li>
<li>We can also try calculating direct specular occlussion in the ray tracing step</li>
<li>The bilateral filter does not have separability property, so it will have poor performance on large kernel dimensions. Consider replacing it by <a href="https://kaiminghe.github.io/eccv10/index.html">Guided Image Filtering</a> since this algorithm has this property</li>
<li>Current implementation of hierarchical ray marching has a <a href="https://youtu.be/MlTohmB4Gh4?t=762">problem</a>. We have to try to fix it</li>
</ul>
<h2><a class="anchor" id="autotoc_md193"></a>
References</h2>
<ul>
<li><b>[AMD-SSSR]</b>: FidelityFX Stochastic Screen-Space Reflections 1.4 - <a href="https://gpuopen.com/manuals/fidelityfx_sdk/fidelityfx_sdk-page_techniques_stochastic-screen-space-reflections/">https://gpuopen.com/manuals/fidelityfx_sdk/fidelityfx_sdk-page_techniques_stochastic-screen-space-reflections/</a></li>
<li><b>[AMD-SPD]</b>: FidelityFX Single Pass Downsampler - <a href="https://gpuopen.com/manuals/fidelityfx_sdk/fidelityfx_sdk-page_techniques_single-pass-downsampler/">https://gpuopen.com/manuals/fidelityfx_sdk/fidelityfx_sdk-page_techniques_single-pass-downsampler/</a></li>
<li><b>[EA-SSRR]</b> Frostbite presentations on Stochastic Screen Space Reflections - <a href="https://www.ea.com/frostbite/news/stochastic-screen-space-reflections">https://www.ea.com/frostbite/news/stochastic-screen-space-reflections</a></li>
<li><b>[EA-HYRTR]</b> EA Seed presentation on Hybrid Real-Time Rendering - <a href="https://www.ea.com/seed/news/seed-dd18-presentation-slides-raytracing">https://www.ea.com/seed/news/seed-dd18-presentation-slides-raytracing</a></li>
<li><b>[Eric Heitz, VNDF]</b> Eric Heitz' paper on VNDF - <a href="http://jcgt.org/published/0007/04/01/">http://jcgt.org/published/0007/04/01/</a></li>
<li><b>[Eric Heitz, Blue Noise]</b> Eric Heitz' paper on Blue Noise sampling - <a href="https://eheitzresearch.wordpress.com/762-2/">https://eheitzresearch.wordpress.com/762-2/</a></li>
<li><b>[Kostas Anagnostou, SSSR]</b> Notes on Screen-Space Reflections with FidelityFX SSSR - <a href="https://interplayoflight.wordpress.com/2022/09/28/notes-on-screenspace-reflections-with-fidelityfx-sssr/">https://interplayoflight.wordpress.com/2022/09/28/notes-on-screenspace-reflections-with-fidelityfx-sssr/</a></li>
<li><b>[Thorsten Thormählen, IBL]</b> Graphics Programming Image-based Lighting - <a href="https://www.mathematik.uni-marburg.de/~thormae/lectures/graphics1/graphics_10_2_eng_web.html#1">https://www.mathematik.uni-marburg.de/~thormae/lectures/graphics1/graphics_10_2_eng_web.html#1</a></li>
<li><b>[Brian Karis, PBR]</b> Brian Karis: Real Shading in Unreal Engine 4, SIGGRAPH 2013 Course: Physically Based Shading in Theory and Practice - <a href="https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf">https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf</a></li>
<li><b>[Mike Turitzin, Hi-Z]</b> Hierarchical Depth Buffers - <a href="https://miketuritzin.com/post/hierarchical-depth-buffers/">https://miketuritzin.com/post/hierarchical-depth-buffers/</a></li>
<li><b>[Christoph Schied, SVGF]</b> Spatiotemporal Variance-Guided Filtering - <a href="https://cg.ivd.kit.edu/publications/2017/svgf/svgf_preprint.pdf">https://cg.ivd.kit.edu/publications/2017/svgf/svgf_preprint.pdf</a></li>
<li><b>[Wiki, Bilateral filter]</b> - Bilateral filter <a href="https://en.wikipedia.org/wiki/Bilateral_filter">https://en.wikipedia.org/wiki/Bilateral_filter</a>   </li>
</ul>
</div><h2 class="groupheader">Member Enumeration Documentation</h2>
<a id="a993695a4851f4ef7bd036f866adbad3b" name="a993695a4851f4ef7bd036f866adbad3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a993695a4851f4ef7bd036f866adbad3b">&#9670;&#160;</a></span>FEATURE_FLAGS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="#a993695a4851f4ef7bd036f866adbad3b">Diligent::ScreenSpaceReflection::FEATURE_FLAGS</a> : <a class="el" href="../../d7/dca/namespaceDiligent.html#a9e27ac38f8dccaa4b4f8e967cd1e868e">Uint32</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Feature flags that control the behavior of the effect. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a993695a4851f4ef7bd036f866adbad3ba2004d8945dc394d431694e3c97a2a093" name="a993695a4851f4ef7bd036f866adbad3ba2004d8945dc394d431694e3c97a2a093"></a>FEATURE_FLAG_NONE&#160;</td><td class="fielddoc"><p>No feature flags are set. </p>
</td></tr>
</table>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.13.2-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../d7/dca/namespaceDiligent.html">Diligent</a></li><li class="navelem"><a class="el" href="../../db/d6a/classDiligent_1_1ScreenSpaceReflection.html">ScreenSpaceReflection</a></li>
    <li class="footer">
      <a href="https://diligentgraphics.com">
        <img class="footer" src="https://github.com/DiligentGraphics/DiligentCore/raw/master/media/diligentgraphics-logo.png" width="99" height="32" alt="Diligent Graphics" />
      </a>
    </li>
  </ul>
</div>
</body>
</html>
